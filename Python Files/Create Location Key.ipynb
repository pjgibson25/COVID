{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "subs = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'D.C.': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in JHU Data\n",
    "JHU_data =  pd.read_csv('../JHU dataset/JHU_filtered_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locs_np = np.array(JHU_data['Province/State'])\n",
    "\n",
    "states_list = []\n",
    "counties_list = []\n",
    "\n",
    "for i in np.arange(0,len(locs_np)):\n",
    "    loc = locs_np[i]\n",
    "    both = loc.split(',')\n",
    "    county = both[0].rstrip().lstrip()\n",
    "    state = both[1].rstrip().lstrip()\n",
    "    states_list.append(state)\n",
    "    counties_list.append(county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = pd.DataFrame(states_list, columns=['State'])\n",
    "counties = pd.DataFrame(counties_list, columns=['Province'])\n",
    "\n",
    "locations = counties.join(states)\n",
    "cleaned = locations.join(JHU_data)\n",
    "cleaned = cleaned.drop(columns=['Province/State'])\n",
    "cleaned = cleaned.rename(columns={'Country/Region': 'Country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d24 = pd.read_csv('../Daily Updates/Mar 24.csv')\n",
    "d25 = pd.read_csv('../Daily Updates/Mar 25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "long_states = list(d25.State)\n",
    "rev_subs = { v:k for k,v in subs.items()}\n",
    "short_states = [rev_subs.get(item,item)  for item in long_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def COUNTY_STATE(county0,state0):\n",
    "    '''\n",
    "    Converts county and state to combined version.\n",
    "    This reduces confusion between strings with similar meanings\n",
    "    \n",
    "    Input:  'county', 'state'\n",
    "    Return:  'COUNTY,STATE' (without spaces, - , or /)\n",
    "    \n",
    "    \n",
    "    Examples of same meaning, different spellings:  \n",
    "    - Washington, D.C.   &   Washington, DC\n",
    "    - Valdez-Cordova, AK & Valdez Cordova, AK\n",
    "    '''\n",
    "    # uppercase\n",
    "    county1 = county0.upper()\n",
    "    state1 = state0.upper()\n",
    "    # remove trailing/leading spaces and periods and dashes\n",
    "    county2 = county1.replace(' ','').replace('.','').replace('/','').replace('-','').replace('COUNTY','').replace('\\'','').replace('PARISH','')\n",
    "    state2 = state1.replace(' ','').replace('.','').replace('/','').replace('-','').replace('COUNTY','').replace('\\'','').replace('PARISH','')\n",
    "    # combine for key\n",
    "    string = county2+','+state2\n",
    "    return string\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# create FIPS array with unique and distinguishable county/state tags\n",
    "#\n",
    "#  -this eliminates problems associated with capital letters and symbols\n",
    "##############################################################################\n",
    "\n",
    "fips = pd.read_csv('../FIPS_tags/FIPS_county_state.csv')\n",
    "fips_np = np.array(fips)\n",
    "name_list = []\n",
    "\n",
    "for i in np.arange(0,len(fips_np)):\n",
    "    string = COUNTY_STATE(fips_np[i,1],fips_np[i,2])\n",
    "    name_list.append(string)\n",
    "\n",
    "fips_names = np.column_stack((fips_np[:,0],np.array(name_list)))\n",
    "code_caps = pd.DataFrame(fips_names, columns=['FIPS code','COUNTY,STATE'])\n",
    "\n",
    "############ Save to CSV file.  Previously unhashed ################\n",
    "code_caps.to_csv('../FIPS_tags/code_COUNTYSTATE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3232\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b530a595f4e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfips_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfips_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0maverage_lat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0maverage_lon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b530a595f4e1>\u001b[0m in \u001b[0;36mavg_loc\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mlcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfips_long\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlcode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfips_long\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Isolate only census tract plots in region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b530a595f4e1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mlcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfips_long\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlcode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfips_long\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Isolate only census tract plots in region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def COUNTY_STATE(county0,state0):\n",
    "    '''\n",
    "    Converts county and state to combined version.\n",
    "    This reduces confusion between strings with similar meanings\n",
    "    \n",
    "    Input:  'county', 'state'\n",
    "    Return:  'COUNTY,STATE' (without spaces, - , or /)\n",
    "    \n",
    "    \n",
    "    Examples of same meaning, different spellings:  \n",
    "    - Washington, D.C.   &   Washington, DC\n",
    "    - Valdez-Cordova, AK & Valdez Cordova, AK\n",
    "    '''\n",
    "    # uppercase\n",
    "    county1 = county0.upper()\n",
    "    state1 = state0.upper()\n",
    "    # remove trailing/leading spaces and periods and dashes\n",
    "    county2 = county1.replace(' ','').replace('.','').replace('/','').replace('-','').replace('COUNTY','').replace('\\'','').replace('PARISH','')\n",
    "    state2 = state1.replace(' ','').replace('.','').replace('/','').replace('-','').replace('COUNTY','').replace('\\'','').replace('PARISH','')\n",
    "    # combine for key\n",
    "    string = county2+','+state2\n",
    "    return string\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# create FIPS array with unique and distinguishable county/state tags\n",
    "#\n",
    "#  -this eliminates problems associated with capital letters and symbols\n",
    "##############################################################################\n",
    "\n",
    "fips = pd.read_csv('../FIPS_tags/FIPS_county_state.csv')\n",
    "fips_np = np.array(fips)\n",
    "name_list = []\n",
    "\n",
    "for i in np.arange(0,len(fips_np)):\n",
    "    string = COUNTY_STATE(fips_np[i,1],fips_np[i,2])\n",
    "    name_list.append(string)\n",
    "\n",
    "fips_names = np.column_stack((fips_np[:,0],np.array(name_list)))\n",
    "code_caps = pd.DataFrame(fips_names, columns=['FIPS code','COUNTY,STATE'])\n",
    "\n",
    "############ Save to CSV file.  Previously unhashed ################\n",
    "#code_caps.to_csv('../FIPS_tags/code_COUNTYSTATE.csv',index=False)\n",
    "\n",
    "##############################################################################\n",
    "# Analyze cencus data to find GPS coordinates for counties\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "\n",
    "census = np.array(pd.read_csv('../FIPS_tags/cbg_geographic_data.csv'))\n",
    "fips_long = census[:,0].astype(str)\n",
    "# Convert latitudes and longitudes to radians\n",
    "lat = np.deg2rad(census[:,-2])\n",
    "lon = np.deg2rad(census[:,-1])\n",
    "#Convert lat/lon (must be in radians) to Cartesian coordinates for each location.\n",
    "X = np.cos(lat) * np.cos(lon)\n",
    "Y = np.cos(lat) * np.sin(lon)\n",
    "Z = np.sin(lat)\n",
    "\n",
    "\n",
    "def avg_loc(code):\n",
    "    code = str(code)\n",
    "    lcode = int(len(code))\n",
    "    cond = [fips_long[i][:lcode] == code for i in np.arange(0,len(fips_long))]\n",
    "    # Isolate only census tract plots in region\n",
    "    if sum(cond) == 0:\n",
    "        return '.','.'\n",
    "    \n",
    "    else:\n",
    "        x1 = X[cond]\n",
    "        y1 = Y[cond]\n",
    "        z1 = Z[cond]\n",
    "        # Take average\n",
    "        x = np.average(x1)\n",
    "        y = np.average(y1)\n",
    "        z = np.average(z1)\n",
    "        # convert average to lat and lon\n",
    "        Lon = np.arctan2(y, x)\n",
    "        Hyp = np.sqrt(x * x + y * y)\n",
    "        Lat = np.arctan2(z, Hyp)\n",
    "        return str(np.rad2deg(Lat)), str(np.rad2deg(Lon))\n",
    "\n",
    "######################################################################\n",
    "# Find lat and longitude for all FIPS county codes.\n",
    "#\n",
    "# Procedure:\n",
    "#     - Use census tract plot data points within county\n",
    "#         * If no tract plots given in census: lat, lon = '.'\n",
    "#     - Convert to cartesian, average, convert to lat/lon\n",
    "#  \n",
    "#\n",
    "# Runtime: about 10/15 minutes.  Likely inefficient but only runs once\n",
    "######################################################################\n",
    "\n",
    "average_lat = []\n",
    "average_lon = []\n",
    "\n",
    "for i in np.arange(0,len(fips_names)):\n",
    "    code = fips_names[i,0]\n",
    "    loc = avg_loc(code)\n",
    "    average_lat.append(loc[0])\n",
    "    average_lon.append(loc[1])\n",
    "    if i%200 == 0:\n",
    "        print(len(fips_names)-i)\n",
    "        \n",
    "        \n",
    "######################################################################\n",
    "\n",
    "# Create Dataframe stating country \n",
    "country = np.chararray((len(fips)), itemsize=10)\n",
    "country[:] = 'US'\n",
    "country = pd.DataFrame(country.decode('utf-8'),columns=['Country'])\n",
    "# Make latitudes and longitudes into Pandas Dataframe\n",
    "latitude_final = pd.DataFrame(average_lat, columns=['Lat'])\n",
    "longitude_final = pd.DataFrame(average_lon, columns=['Lat'])\n",
    "# Combine all columns\n",
    "location_array = pd.concat([fips, country,latitude_final,longitude_final], axis=1)\n",
    "\n",
    "\n",
    "############ Save to CSV file.  Previously unhashed ################\n",
    "#location_array.to_csv('../FIPS_tags/locationkey_without_flag.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
