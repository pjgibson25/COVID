{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "subs = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'D.C.': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in JHU Data\n",
    "JHU_data =  pd.read_csv('../JHU dataset/JHU_filtered_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_np = np.array(JHU_data['Province/State'])\n",
    "\n",
    "states_list = []\n",
    "counties_list = []\n",
    "\n",
    "for i in np.arange(0,len(locs_np)):\n",
    "    loc = locs_np[i]\n",
    "    both = loc.split(',')\n",
    "    county = both[0].rstrip().lstrip()\n",
    "    state = both[1].rstrip().lstrip()\n",
    "    states_list.append(state)\n",
    "    counties_list.append(county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.DataFrame(states_list, columns=['State'])\n",
    "counties = pd.DataFrame(counties_list, columns=['Province'])\n",
    "\n",
    "locations = counties.join(states)\n",
    "cleaned = locations.join(JHU_data)\n",
    "cleaned = cleaned.drop(columns=['Province/State'])\n",
    "cleaned = cleaned.rename(columns={'Country/Region': 'Country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d24 = pd.read_csv('../Daily Updates/Mar 24.csv')\n",
    "d25 = pd.read_csv('../Daily Updates/Mar 25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_states = list(d25.State)\n",
    "rev_subs = { v:k for k,v in subs.items()}\n",
    "short_states = [rev_subs.get(item,item)  for item in long_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def COUNTY_STATE(county0,state0):\n",
    "    '''\n",
    "    Converts county and state to combined version.\n",
    "    This reduces confusion between strings with similar meanings\n",
    "    \n",
    "    Input:  'county', 'state'\n",
    "    Return:  'COUNTY,STATE' (without spaces, - , or /)\n",
    "    \n",
    "    \n",
    "    Examples of same meaning, different spellings:  \n",
    "    - Washington, D.C.   &   Washington, DC\n",
    "    - Valdez-Cordova, AK & Valdez Cordova, AK\n",
    "    '''\n",
    "    # uppercase\n",
    "    county1 = county0.upper()\n",
    "    state1 = state0.upper()\n",
    "    # remove trailing/leading spaces and periods and dashes\n",
    "    county2 = county1.replace(' ','').replace('.','').replace('/','').replace('-','').replace('COUNTY','').replace('\\'','').replace('PARISH','')\n",
    "    state2 = state1.replace(' ','').replace('.','').replace('/','').replace('-','').replace('COUNTY','').replace('\\'','').replace('PARISH','')\n",
    "    # combine for key\n",
    "    string = county2+','+state2\n",
    "    return string\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# create FIPS array with unique and distinguishable county/state tags\n",
    "#\n",
    "#  -this eliminates problems associated with capital letters and symbols\n",
    "##############################################################################\n",
    "\n",
    "fips = pd.read_csv('../FIPS_tags/FIPS_county_state.csv')\n",
    "fips_np = np.array(fips)\n",
    "name_list = []\n",
    "\n",
    "fips_str = fips_np[:,0].astype(str)\n",
    "for i in np.arange(0,len(fips_str)):\n",
    "    fips_one = fips_str[i]\n",
    "    if len(fips_one) == 4:\n",
    "        fips_one = '0'+fips_one\n",
    "    fips_str[i] = fips_one\n",
    "\n",
    "for i in np.arange(0,len(fips_np)):\n",
    "    string = COUNTY_STATE(fips_np[i,1],fips_np[i,2])\n",
    "    name_list.append(string)\n",
    "\n",
    "fips_names = np.column_stack((fips_str,np.array(name_list)))\n",
    "code_caps = pd.DataFrame(fips_names, columns=['FIPS code','COUNTY,STATE'])\n",
    "\n",
    "############ Save to CSV file.  Previously unhashed ################\n",
    "code_caps.to_csv('../FIPS_tags/code_COUNTYSTATE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS code</th>\n",
       "      <th>COUNTY,STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>AUTAUGA,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01003</td>\n",
       "      <td>BALDWIN,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01005</td>\n",
       "      <td>BARBOUR,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01007</td>\n",
       "      <td>BIBB,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01009</td>\n",
       "      <td>BLOUNT,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01011</td>\n",
       "      <td>BULLOCK,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01013</td>\n",
       "      <td>BUTLER,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01015</td>\n",
       "      <td>CALHOUN,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01017</td>\n",
       "      <td>CHAMBERS,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01019</td>\n",
       "      <td>CHEROKEE,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01021</td>\n",
       "      <td>CHILTON,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01023</td>\n",
       "      <td>CHOCTAW,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01025</td>\n",
       "      <td>CLARKE,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01027</td>\n",
       "      <td>CLAY,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01029</td>\n",
       "      <td>CLEBURNE,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>01031</td>\n",
       "      <td>COFFEE,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>01033</td>\n",
       "      <td>COLBERT,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01035</td>\n",
       "      <td>CONECUH,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>01037</td>\n",
       "      <td>COOSA,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01039</td>\n",
       "      <td>COVINGTON,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>01041</td>\n",
       "      <td>CRENSHAW,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>01043</td>\n",
       "      <td>CULLMAN,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>01045</td>\n",
       "      <td>DALE,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>01047</td>\n",
       "      <td>DALLAS,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>01049</td>\n",
       "      <td>DEKALB,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>01051</td>\n",
       "      <td>ELMORE,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>01053</td>\n",
       "      <td>ESCAMBIA,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>01055</td>\n",
       "      <td>ETOWAH,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>01057</td>\n",
       "      <td>FAYETTE,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>01059</td>\n",
       "      <td>FRANKLIN,AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>72101</td>\n",
       "      <td>MOROVIS,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>72103</td>\n",
       "      <td>NABUABO,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>72105</td>\n",
       "      <td>NARANJITO,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>72107</td>\n",
       "      <td>OROCOVIS,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>72109</td>\n",
       "      <td>PATILLAS,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>72111</td>\n",
       "      <td>PENUELAS,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>72113</td>\n",
       "      <td>PONCE,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>72115</td>\n",
       "      <td>QUEBRADILLAS,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>72117</td>\n",
       "      <td>RINCON,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>72119</td>\n",
       "      <td>RIOGRANDE,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>72121</td>\n",
       "      <td>SABANAGRANDE,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>72123</td>\n",
       "      <td>SALINAS,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>72125</td>\n",
       "      <td>SANGERMAN,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>72127</td>\n",
       "      <td>SANJUAN,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>72129</td>\n",
       "      <td>SANLORENZO,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>72131</td>\n",
       "      <td>SANSABASTIAN,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>72133</td>\n",
       "      <td>SANTAISABEL,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>72135</td>\n",
       "      <td>TOAALTA,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>72137</td>\n",
       "      <td>TOABAJA,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>72139</td>\n",
       "      <td>TRUJILLOALTO,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>72141</td>\n",
       "      <td>UTUADO,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>72143</td>\n",
       "      <td>VEGAALTA,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>72145</td>\n",
       "      <td>VEGABAJA,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>72147</td>\n",
       "      <td>VIEQUES,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>72149</td>\n",
       "      <td>VILLALBA,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>72151</td>\n",
       "      <td>YABUCOA,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>72153</td>\n",
       "      <td>YAUCO,PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>78010</td>\n",
       "      <td>STCROIX,VI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>78020</td>\n",
       "      <td>STJOHN,VI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>78030</td>\n",
       "      <td>STTHOMAS,VI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3232 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FIPS code     COUNTY,STATE\n",
       "0        01001       AUTAUGA,AL\n",
       "1        01003       BALDWIN,AL\n",
       "2        01005       BARBOUR,AL\n",
       "3        01007          BIBB,AL\n",
       "4        01009        BLOUNT,AL\n",
       "5        01011       BULLOCK,AL\n",
       "6        01013        BUTLER,AL\n",
       "7        01015       CALHOUN,AL\n",
       "8        01017      CHAMBERS,AL\n",
       "9        01019      CHEROKEE,AL\n",
       "10       01021       CHILTON,AL\n",
       "11       01023       CHOCTAW,AL\n",
       "12       01025        CLARKE,AL\n",
       "13       01027          CLAY,AL\n",
       "14       01029      CLEBURNE,AL\n",
       "15       01031        COFFEE,AL\n",
       "16       01033       COLBERT,AL\n",
       "17       01035       CONECUH,AL\n",
       "18       01037         COOSA,AL\n",
       "19       01039     COVINGTON,AL\n",
       "20       01041      CRENSHAW,AL\n",
       "21       01043       CULLMAN,AL\n",
       "22       01045          DALE,AL\n",
       "23       01047        DALLAS,AL\n",
       "24       01049        DEKALB,AL\n",
       "25       01051        ELMORE,AL\n",
       "26       01053      ESCAMBIA,AL\n",
       "27       01055        ETOWAH,AL\n",
       "28       01057       FAYETTE,AL\n",
       "29       01059      FRANKLIN,AL\n",
       "...        ...              ...\n",
       "3202     72101       MOROVIS,PR\n",
       "3203     72103       NABUABO,PR\n",
       "3204     72105     NARANJITO,PR\n",
       "3205     72107      OROCOVIS,PR\n",
       "3206     72109      PATILLAS,PR\n",
       "3207     72111      PENUELAS,PR\n",
       "3208     72113         PONCE,PR\n",
       "3209     72115  QUEBRADILLAS,PR\n",
       "3210     72117        RINCON,PR\n",
       "3211     72119     RIOGRANDE,PR\n",
       "3212     72121  SABANAGRANDE,PR\n",
       "3213     72123       SALINAS,PR\n",
       "3214     72125     SANGERMAN,PR\n",
       "3215     72127       SANJUAN,PR\n",
       "3216     72129    SANLORENZO,PR\n",
       "3217     72131  SANSABASTIAN,PR\n",
       "3218     72133   SANTAISABEL,PR\n",
       "3219     72135       TOAALTA,PR\n",
       "3220     72137       TOABAJA,PR\n",
       "3221     72139  TRUJILLOALTO,PR\n",
       "3222     72141        UTUADO,PR\n",
       "3223     72143      VEGAALTA,PR\n",
       "3224     72145      VEGABAJA,PR\n",
       "3225     72147       VIEQUES,PR\n",
       "3226     72149      VILLALBA,PR\n",
       "3227     72151       YABUCOA,PR\n",
       "3228     72153         YAUCO,PR\n",
       "3229     78010       STCROIX,VI\n",
       "3230     78020        STJOHN,VI\n",
       "3231     78030      STTHOMAS,VI\n",
       "\n",
       "[3232 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01001', '01003', '01005', ..., '78010', '78020', '78030'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3232\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b530a595f4e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfips_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfips_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0maverage_lat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0maverage_lon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b530a595f4e1>\u001b[0m in \u001b[0;36mavg_loc\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mlcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfips_long\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlcode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfips_long\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Isolate only census tract plots in region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b530a595f4e1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mlcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfips_long\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlcode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfips_long\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Isolate only census tract plots in region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def COUNTY_STATE(county0,state0):\n",
    "    '''\n",
    "    Converts county and state to combined version.\n",
    "    This reduces confusion between strings with similar meanings\n",
    "    \n",
    "    Input:  'county', 'state'\n",
    "    Return:  'COUNTY,STATE' (without spaces, - , or /)\n",
    "    \n",
    "    \n",
    "    Examples of same meaning, different spellings:  \n",
    "    - Washington, D.C.   &   Washington, DC\n",
    "    - Valdez-Cordova, AK & Valdez Cordova, AK\n",
    "    '''\n",
    "    # uppercase\n",
    "    county1 = county0.upper()\n",
    "    state1 = state0.upper()\n",
    "    # remove trailing/leading spaces and periods and dashes\n",
    "    county2 = county1.replace(' ','').replace('.','').replace('/','').replace('-','').replace('COUNTY','').replace('\\'','').replace('PARISH','')\n",
    "    state2 = state1.replace(' ','').replace('.','').replace('/','').replace('-','').replace('COUNTY','').replace('\\'','').replace('PARISH','')\n",
    "    # combine for key\n",
    "    string = county2+','+state2\n",
    "    return string\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# create FIPS array with unique and distinguishable county/state tags\n",
    "#\n",
    "#  -this eliminates problems associated with capital letters and symbols\n",
    "##############################################################################\n",
    "\n",
    "fips = pd.read_csv('../FIPS_tags/FIPS_county_state.csv')\n",
    "fips_np = np.array(fips)\n",
    "name_list = []\n",
    "\n",
    "for i in np.arange(0,len(fips_np)):\n",
    "    string = COUNTY_STATE(fips_np[i,1],fips_np[i,2])\n",
    "    name_list.append(string)\n",
    "\n",
    "fips_names = np.column_stack((fips_np[:,0],np.array(name_list)))\n",
    "code_caps = pd.DataFrame(fips_names, columns=['FIPS code','COUNTY,STATE'])\n",
    "\n",
    "############ Save to CSV file.  Previously unhashed ################\n",
    "#code_caps.to_csv('../FIPS_tags/code_COUNTYSTATE.csv',index=False)\n",
    "\n",
    "##############################################################################\n",
    "# Analyze cencus data to find GPS coordinates for counties\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "\n",
    "census = np.array(pd.read_csv('../FIPS_tags/cbg_geographic_data.csv'))\n",
    "fips_long = census[:,0].astype(str)\n",
    "# Convert latitudes and longitudes to radians\n",
    "lat = np.deg2rad(census[:,-2])\n",
    "lon = np.deg2rad(census[:,-1])\n",
    "#Convert lat/lon (must be in radians) to Cartesian coordinates for each location.\n",
    "X = np.cos(lat) * np.cos(lon)\n",
    "Y = np.cos(lat) * np.sin(lon)\n",
    "Z = np.sin(lat)\n",
    "\n",
    "\n",
    "def avg_loc(code):\n",
    "    code = str(code)\n",
    "    lcode = int(len(code))\n",
    "    cond = [fips_long[i][:lcode] == code for i in np.arange(0,len(fips_long))]\n",
    "    # Isolate only census tract plots in region\n",
    "    if sum(cond) == 0:\n",
    "        return '.','.'\n",
    "    \n",
    "    else:\n",
    "        x1 = X[cond]\n",
    "        y1 = Y[cond]\n",
    "        z1 = Z[cond]\n",
    "        # Take average\n",
    "        x = np.average(x1)\n",
    "        y = np.average(y1)\n",
    "        z = np.average(z1)\n",
    "        # convert average to lat and lon\n",
    "        Lon = np.arctan2(y, x)\n",
    "        Hyp = np.sqrt(x * x + y * y)\n",
    "        Lat = np.arctan2(z, Hyp)\n",
    "        return str(np.rad2deg(Lat)), str(np.rad2deg(Lon))\n",
    "\n",
    "######################################################################\n",
    "# Find lat and longitude for all FIPS county codes.\n",
    "#\n",
    "# Procedure:\n",
    "#     - Use census tract plot data points within county\n",
    "#         * If no tract plots given in census: lat, lon = '.'\n",
    "#     - Convert to cartesian, average, convert to lat/lon\n",
    "#  \n",
    "#\n",
    "# Runtime: about 10/15 minutes.  Likely inefficient but only runs once\n",
    "######################################################################\n",
    "\n",
    "average_lat = []\n",
    "average_lon = []\n",
    "\n",
    "for i in np.arange(0,len(fips_names)):\n",
    "    code = fips_names[i,0]\n",
    "    loc = avg_loc(code)\n",
    "    average_lat.append(loc[0])\n",
    "    average_lon.append(loc[1])\n",
    "    if i%200 == 0:\n",
    "        print(len(fips_names)-i)\n",
    "        \n",
    "        \n",
    "######################################################################\n",
    "\n",
    "# Create Dataframe stating country \n",
    "country = np.chararray((len(fips)), itemsize=10)\n",
    "country[:] = 'US'\n",
    "country = pd.DataFrame(country.decode('utf-8'),columns=['Country'])\n",
    "# Make latitudes and longitudes into Pandas Dataframe\n",
    "latitude_final = pd.DataFrame(average_lat, columns=['Lat'])\n",
    "longitude_final = pd.DataFrame(average_lon, columns=['Lat'])\n",
    "# Combine all columns\n",
    "location_array = pd.concat([fips, country,latitude_final,longitude_final], axis=1)\n",
    "\n",
    "\n",
    "############ Save to CSV file.  Previously unhashed ################\n",
    "#location_array.to_csv('../FIPS_tags/locationkey_without_flag.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
